#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å„ªåŒ– Jekyll æ–‡ç« æ¨™ç±¤
"""

import os
import re
from pathlib import Path
from collections import defaultdict

# æ¨™ç±¤æ˜ å°„è¡¨ - èˆŠæ¨™ç±¤ -> æ–°æ¨™ç±¤
TAG_MAPPING = {
    # åˆä½µç›¸ä¼¼æ¨™ç±¤
    "aws-ec2": "aws",
    "aws-lambda": "aws",
    "k8s": "kubernetes",
    "kubeadm": "kubernetes",
    "kubectl": "kubernetes",
    "meidum": "medium",
    "github-pages": "github",
    
    # æ¨™æº–åŒ–æ ¼å¼
    "deep-learning": "machine-learning",
    "deepvariant": "bioinformatics",
    "netflow": "workflow",
    "nfs-server": "storage",
    "memorydb": "database",
    "documentdb": "database",
    "elasticache": "cache",
    "elb": "load-balancer",
    "sns": "messaging",
    "ecg": "medical-ai",
    "resnet": "cnn",
    "v100": "gpu",
    "jetson-nano": "edge-computing",
    "tensorrt": "ai-optimization",
    "cpython": "python",
    "multiprocess": "parallel-computing",
    "multithread": "parallel-computing",
    "paramiko": "ssh",
    "crawler": "web-scraping",
    "hashable": "data-structure",
    "cprofile": "performance",
    "numba": "performance",
    "axel": "download-tools",
    "filesystem": "storage",
    "containers": "containerization",
    "podman": "containerization",
    "ansible": "automation",
    "mlflow": "mlops",
    "jupyter": "data-science",
    "big-data": "data-engineering",
    "llama-3": "llm",
    "google-gemini": "ai-api",
    "notion": "productivity",
    "color-blindness": "accessibility",
    "business-model-innovation": "business",
    "subscription": "business",
    "scrum": "agile",
    "biology": "bioinformatics",
    "gene": "bioinformatics",
    "paper": "research",
    "life": "personal",
    "technology": "tech",
    "schedule": "workflow",
    "backup": "devops",
    "convert": "tools",
    "automotive": "industry",
    "storage": "infrastructure",
    "gpu": "hardware",
    "tensorflow": "machine-learning",
    "data-science": "analytics",
    "workflow": "automation",
    "hdfs": "distributed-storage",
    "hadoop": "big-data",
    "ubuntu": "linux",
    "ec2": "aws",
    "netflow": "workflow",
    "ecg": "medical-ai",
    "cnn": "deep-learning",
    "jekyll": "static-site",
    "ruby": "programming-language",
    "cloud": "cloud-computing",
    "automation": "devops",
    "machine-learning": "ai",
    "ai": "artificial-intelligence"
}

# ç‚ºæ²’æœ‰æ¨™ç±¤çš„æ–‡ç« æ·»åŠ æ¨™ç±¤
MISSING_TAGS = {
    "2019-01-19-c04fee852539.md": ["data-science", "analytics", "business"],
    "2019-01-15-f555d1eb6e34.md": ["data-science", "analytics", "business"],
    "2019-01-24-de47a58680d5.md": ["data-science", "analytics", "business"]
}

def normalize_tag(tag):
    """æ¨™æº–åŒ–æ¨™ç±¤æ ¼å¼"""
    # è½‰æ›ç‚ºå°å¯«
    tag = tag.lower()
    # æ›¿æ›ç©ºæ ¼ç‚ºé€£å­—è™Ÿ
    tag = re.sub(r'\s+', '-', tag)
    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
    tag = re.sub(r'[^a-z0-9\-]', '', tag)
    # ç§»é™¤å¤šé¤˜çš„é€£å­—è™Ÿ
    tag = re.sub(r'-+', '-', tag)
    # ç§»é™¤é–‹é ­å’Œçµå°¾çš„é€£å­—è™Ÿ
    tag = tag.strip('-')
    return tag

def update_tags_in_file(file_path):
    """æ›´æ–°å–®å€‹æª”æ¡ˆçš„æ¨™ç±¤"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except UnicodeDecodeError:
        try:
            with open(file_path, 'r', encoding='latin-1') as f:
                content = f.read()
        except:
            print(f"ç„¡æ³•è®€å–æª”æ¡ˆ: {file_path}")
            return False
    
    original_content = content
    updated = False
    
    # æª¢æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ æ¨™ç±¤
    filename = Path(file_path).name
    if filename in MISSING_TAGS:
        # å°‹æ‰¾ tags: è¡Œ
        tags_match = re.search(r'^tags:\s*\[.*?\]', content, re.MULTILINE)
        if tags_match:
            # æ›¿æ›ç¾æœ‰çš„ç©ºæ¨™ç±¤
            new_tags = '[' + ', '.join(f'"{tag}"' for tag in MISSING_TAGS[filename]) + ']'
            content = re.sub(r'^tags:\s*\[.*?\]', f'tags: {new_tags}', content, flags=re.MULTILINE)
            updated = True
            print(f"âœ… ç‚º {filename} æ·»åŠ æ¨™ç±¤: {MISSING_TAGS[filename]}")
    
    # æ›´æ–°ç¾æœ‰æ¨™ç±¤
    tags_match = re.search(r'^tags:\s*\[(.*?)\]', content, re.MULTILINE)
    if tags_match:
        tags_str = tags_match.group(1)
        old_tags = []
        for tag in tags_str.split(','):
            tag = tag.strip().strip('"\'')
            if tag:
                old_tags.append(tag)
        
        if old_tags:
            new_tags = []
            for tag in old_tags:
                # æ‡‰ç”¨æ¨™ç±¤æ˜ å°„
                if tag in TAG_MAPPING:
                    new_tag = TAG_MAPPING[tag]
                    new_tags.append(new_tag)
                    print(f"ğŸ”„ æ¨™ç±¤æ˜ å°„: {tag} -> {new_tag}")
                else:
                    # æ¨™æº–åŒ–æ ¼å¼
                    normalized_tag = normalize_tag(tag)
                    if normalized_tag != tag:
                        new_tags.append(normalized_tag)
                        print(f"ğŸ”§ æ¨™æº–åŒ–æ¨™ç±¤: {tag} -> {normalized_tag}")
                    else:
                        new_tags.append(tag)
            
            # å»é‡ä¸¦æ’åº
            new_tags = sorted(list(set(new_tags)))
            
            # æ›´æ–°æª”æ¡ˆå…§å®¹
            new_tags_str = '[' + ', '.join(f'"{tag}"' for tag in new_tags) + ']'
            content = re.sub(r'^tags:\s*\[.*?\]', f'tags: {new_tags_str}', content, flags=re.MULTILINE)
            updated = True
    
    # å¯«å…¥æ›´æ–°å¾Œçš„å…§å®¹
    if updated and content != original_content:
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            return True
        except Exception as e:
            print(f"âŒ å¯«å…¥æª”æ¡ˆå¤±æ•— {file_path}: {e}")
            return False
    
    return False

def optimize_all_tags():
    """å„ªåŒ–æ‰€æœ‰æ–‡ç« çš„æ¨™ç±¤"""
    posts_dir = Path("jekyll-site/_posts")
    
    if not posts_dir.exists():
        print("æ‰¾ä¸åˆ° _posts ç›®éŒ„")
        return
    
    updated_files = 0
    total_files = 0
    
    print("ğŸš€ é–‹å§‹å„ªåŒ–æ–‡ç« æ¨™ç±¤...")
    print("=" * 60)
    
    # éæ­·æ‰€æœ‰æ–‡ç« 
    for post_file in posts_dir.rglob("*.md"):
        if post_file.name.startswith('.'):
            continue
        
        total_files += 1
        print(f"\nğŸ“ è™•ç†: {post_file.name}")
        
        if update_tags_in_file(post_file):
            updated_files += 1
    
    print("\n" + "=" * 60)
    print("âœ… æ¨™ç±¤å„ªåŒ–å®Œæˆï¼")
    print(f"ğŸ“Š ç¸½æª”æ¡ˆæ•¸: {total_files}")
    print(f"ğŸ”„ æ›´æ–°æª”æ¡ˆæ•¸: {updated_files}")
    print(f"ğŸ“ˆ æ›´æ–°ç‡: {updated_files/total_files*100:.1f}%")
    
    # é¡¯ç¤ºæ¨™ç±¤çµ±è¨ˆ
    print("\nğŸ“‹ æ–°çš„æ¨™ç±¤åˆ†é¡å»ºè­°:")
    print("ğŸ·ï¸  æŠ€è¡“é¡: python, aws, kubernetes, docker, git, api")
    print("â˜ï¸  é›²ç«¯é¡: cloud-computing, aws, serverless, load-balancer")
    print("ğŸ¤– AI/MLé¡: artificial-intelligence, machine-learning, deep-learning, cnn")
    print("ğŸ”„ DevOpsé¡: automation, devops, ci-cd, workflow")
    print("ğŸ’¾ è³‡æ–™é¡: data-engineering, analytics, database, storage")
    print("ğŸ”¬ ç ”ç©¶é¡: bioinformatics, research, medical-ai")
    print("ğŸ’¼ å•†æ¥­é¡: business, productivity, agile")

if __name__ == "__main__":
    optimize_all_tags()
